{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaab9ae72954d2d9970257f8938eaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the video\n",
    "video = cv2.VideoCapture('./media/run1.mp4')\n",
    "\n",
    "# Load the face cascade classifier\n",
    "# face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "# Load the face detector model\n",
    "prototxt_path = './models/deploy.prototxt'\n",
    "caffemodel_path = './models/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "face_detector = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize the total number of faces detected\n",
    "total_faces = 0\n",
    "\n",
    "# Create a video widget\n",
    "video_widget = widgets.Output()\n",
    "\n",
    "# Display the video widget\n",
    "display(video_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866de2a25d6a4159b905a7cb2e141807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the total number of faces detected\n",
    "total_faces = 0\n",
    "\n",
    "# Create a video widget\n",
    "video_widget = widgets.Output()\n",
    "\n",
    "# Display the video widget\n",
    "display(video_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/dnn/src/layers/batch_norm_layer.cpp:51: error: (-215:Assertion failed) blobs.size() >= 2 in function 'BatchNormLayerImpl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/Projs/detect_faces/count_faces_vid.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/Projs/detect_faces/count_faces_vid.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Pass the blob through the face detector\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/Projs/detect_faces/count_faces_vid.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m face_detector\u001b[39m.\u001b[39msetInput(blob)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/Projs/detect_faces/count_faces_vid.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m detections \u001b[39m=\u001b[39m face_detector\u001b[39m.\u001b[39;49mforward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/Projs/detect_faces/count_faces_vid.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Loop through each face detection\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/Projs/detect_faces/count_faces_vid.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(detections\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/dnn/src/layers/batch_norm_layer.cpp:51: error: (-215:Assertion failed) blobs.size() >= 2 in function 'BatchNormLayerImpl'\n"
     ]
    }
   ],
   "source": [
    "# Loop through each frame of the video\n",
    "while True:\n",
    "    # Read the frame\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Check if the frame was read successfully\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    frame_resized = cv2.resize(frame, (300, 300))\n",
    "\n",
    "    # Convert the frame to a blob for input to the face detector\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    # Pass the blob through the face detector\n",
    "    face_detector.setInput(blob)\n",
    "    detections = face_detector.forward()\n",
    "\n",
    "    # Loop through each face detection\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Ignore detections with low confidence\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "\n",
    "        # Get the coordinates of the face detection\n",
    "        box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "        (x, y, w, h) = box.astype('int')\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Count the number of faces in the frame\n",
    "    num_faces = detections.shape[2]\n",
    "\n",
    "    # Add the number of faces to the total count\n",
    "    total_faces += num_faces\n",
    "\n",
    "    # Display the total number of faces detected in the frame\n",
    "    cv2.putText(frame, f'Total Faces: {total_faces}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame with detected rectangles in the video widget\n",
    "    with video_widget:\n",
    "        clear_output(wait=True)\n",
    "        _, png = cv2.imencode('.png', frame[:, :, ::-1])\n",
    "        display(widgets.Image(value=png.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the video capture object\n",
    "video.release()\n",
    "\n",
    "# Display the total count of faces detected\n",
    "print('Total faces:', total_faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-kernel",
   "language": "python",
   "name": "trading-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
